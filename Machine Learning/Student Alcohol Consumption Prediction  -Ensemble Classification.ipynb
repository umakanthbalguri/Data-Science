{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>gender</th>\n",
       "      <th>alc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences gender  alc  \n",
       "0       5         2      M    1  \n",
       "1       3         9      M    1  \n",
       "2       5         0      F    0  \n",
       "3       3        10      F    0  \n",
       "4       5         2      M    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"Alc\" i.e Weekend alcohol consumption in the data set:\n",
    "\n",
    "alc = pd.read_csv(\"alcohol.csv\")\n",
    "alc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Test Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(alc, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "health        0\n",
       "absences      0\n",
       "gender        0\n",
       "alc           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for Missing Values\n",
    "train_set.isna().sum()\n",
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the Target Variable\n",
    "train_y = train_set['alc']\n",
    "test_y = test_set['alc']\n",
    "\n",
    "train_inputs = train_set.drop(['alc'], axis=1)\n",
    "test_inputs = test_set.drop(['alc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Deriving new coloumn from Absences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col(df):\n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    df1['absences_binned'] = pd.cut(df1['absences'],\n",
    "                                       bins=[0,1,5,10,20,50],\n",
    "                                       labels=False, \n",
    "                                       include_lowest=True)\n",
    " \n",
    "    return df1[['absences_binned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "Medu           int64\n",
       "Fedu           int64\n",
       "traveltime     int64\n",
       "studytime      int64\n",
       "failures       int64\n",
       "famrel         int64\n",
       "freetime       int64\n",
       "goout          int64\n",
       "health         int64\n",
       "absences       int64\n",
       "gender        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identifying the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the binary columns so we can pass them through without transforming\n",
    "binary_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Column Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'health',\n",
       " 'absences']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = ['absences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n",
    "                               ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, transformed_columns)],\n",
    "        remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66643886,  0.96597412,  0.90362635, ...,  1.        ,\n",
       "         0.        ,  0.77953176],\n",
       "       [ 0.66643886, -0.93881619, -1.68666277, ...,  0.        ,\n",
       "         1.        ,  2.59906354],\n",
       "       [ 0.66643886,  0.33104402,  0.04019664, ...,  0.        ,\n",
       "         1.        , -1.04000003],\n",
       "       ...,\n",
       "       [ 0.66643886, -2.20867639, -2.55009248, ...,  1.        ,\n",
       "         0.        ,  1.68929765],\n",
       "       [ 1.6195814 , -0.30388608, -1.68666277, ...,  0.        ,\n",
       "         1.        ,  1.68929765],\n",
       "       [ 1.6195814 , -0.30388608, -2.55009248, ...,  0.        ,\n",
       "         1.        ,  0.77953176]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transforming the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23800, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23984621,  0.33104402,  1.76705606, ...,  1.        ,\n",
       "         0.        , -0.13023413],\n",
       "       [-1.23984621, -0.30388608,  0.04019664, ...,  0.        ,\n",
       "         1.        , -1.04000003],\n",
       "       [-0.28670367,  0.33104402,  0.04019664, ...,  0.        ,\n",
       "         1.        , -1.04000003],\n",
       "       ...,\n",
       "       [ 0.66643886, -0.30388608,  0.04019664, ...,  1.        ,\n",
       "         0.        , -0.13023413],\n",
       "       [-1.23984621, -0.93881619,  0.04019664, ...,  0.        ,\n",
       "         1.        , -1.04000003],\n",
       "       [-1.23984621,  0.96597412,  0.04019664, ...,  1.        ,\n",
       "         0.        , -1.04000003]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.523487\n",
       "1    0.476513\n",
       "Name: alc, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()/len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard voting classifier (should include at least two models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt',\n",
       "                              DecisionTreeClassifier(max_depth=6,\n",
       "                                                     min_samples_leaf=8,\n",
       "                                                     min_samples_split=5)),\n",
       "                             ('lr1',\n",
       "                              LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('lr2',\n",
       "                              LogisticRegression(C=1, max_iter=10000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('sgd',\n",
       "                              SGDClassifier(l1_ratio=0.8, max_iter=10000))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "dtree_clf = DecisionTreeClassifier(max_depth=6, min_samples_split=5, min_samples_leaf=8)\n",
    "log_clf_1 = LogisticRegression(multi_class='multinomial', solver = 'lbfgs', C=0.1, max_iter=10000)\n",
    "log_clf_2 = LogisticRegression(multi_class='multinomial', solver = 'lbfgs', C=1, max_iter=10000)\n",
    "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3, l1_ratio=0.8)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr1', log_clf_1),\n",
    "                        ('lr2', log_clf_2),\n",
    "                        ('sgd', sgd_clf)],\n",
    "            voting='hard')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8221848739495798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8192156862745098\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft voting classifier (should include at least two models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt',\n",
       "                              DecisionTreeClassifier(max_depth=6,\n",
       "                                                     min_samples_leaf=8,\n",
       "                                                     min_samples_split=5)),\n",
       "                             ('lr1',\n",
       "                              LogisticRegression(C=0.1, max_iter=10000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('lr2',\n",
       "                              LogisticRegression(C=1, max_iter=10000,\n",
       "                                                 multi_class='multinomial'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr1', log_clf_1),\n",
    "                       ('lr2', log_clf_2)],\n",
    "            voting='soft')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8224789915966386\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8203921568627451\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SGDClassifier(), max_samples=1000,\n",
       "                  n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier \n",
    "\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=50, \n",
    "            max_samples=1000, bootstrap=True, n_jobs=-1) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8215546218487395\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.821078431372549\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Patches and Random Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SGDClassifier(), bootstrap=False,\n",
       "                  max_features=14, max_samples=10000, n_estimators=500,\n",
       "                  n_jobs=-1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Patches: see the max_features variable\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=500, max_features=14,\n",
    "            max_samples=10000, bootstrap= False, n_jobs=-1) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.821764705882353\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8214705882352941\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=14, min_samples_leaf=4, min_samples_split=4,\n",
       "                       n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, min_samples_split=4, min_samples_leaf=4,max_depth=14) \n",
    "\n",
    "rnd_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8624789915966387\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = rnd_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8182352941176471\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = rnd_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4,\n",
       "                                                         max_leaf_nodes=6,\n",
       "                                                         min_samples_leaf=7,\n",
       "                                                         splitter='random'),\n",
       "                   learning_rate=0.1, n_estimators=500)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "#Create Adapative Boosting with Decision Stumps (depth=1)\n",
    "ada_clf = AdaBoostClassifier( \n",
    "            DecisionTreeClassifier(max_depth=4, splitter=\"random\", min_samples_leaf=7, max_leaf_nodes=6), n_estimators=500, \n",
    "            algorithm=\"SAMME.R\", learning_rate=0.1) \n",
    "\n",
    "ada_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8375210084033613\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = ada_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8307843137254902\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = ada_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=1000, subsample=0.75)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train on 75% of the sample\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbclf = GradientBoostingClassifier(max_depth=3, n_estimators=1000, \n",
    "                                   learning_rate=0.1, subsample=0.75) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8516806722689075\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8318627450980393\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1A) Stochastic Gradient Boosting Classifier, (with parameters max_depth=3, n_estimators=1000,learning_rate=0.1, subsample=0.75) performs the best as the accuracy for train data is 85.1% and test data is:83.19%. (The baseline is 52.35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
