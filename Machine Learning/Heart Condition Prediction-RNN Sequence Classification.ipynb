{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data\n",
    "data = pd.read_csv(\"heartbeat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9026, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T179</th>\n",
       "      <th>T180</th>\n",
       "      <th>T181</th>\n",
       "      <th>T182</th>\n",
       "      <th>T183</th>\n",
       "      <th>T184</th>\n",
       "      <th>T185</th>\n",
       "      <th>T186</th>\n",
       "      <th>T187</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.626  0.276  0.3250  0.4310  0.3900  0.3940  0.3580  0.3740   \n",
       "\n",
       "      T10  ...  T179  T180  T181  T182  T183  T184  T185  T186  T187  Target  \n",
       "0  0.1380  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "1  0.0781  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "2  0.0857  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "3  0.0155  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "4  0.3620  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Target']\n",
    "x = data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Target variables to array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 3, 2, 0, 0, 2, 0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.931, 0.844, 0.647, ..., 0.   , 0.   , 0.   ],\n",
       "       [1.   , 0.986, 0.721, ..., 0.   , 0.   , 0.   ],\n",
       "       [1.   , 0.928, 0.617, ..., 0.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [1.   , 0.951, 0.495, ..., 0.   , 0.   , 0.   ],\n",
       "       [0.24 , 0.421, 0.607, ..., 0.   , 0.   , 0.   ],\n",
       "       [0.927, 0.767, 0.595, ..., 0.   , 0.   , 0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Data to have 3 dimensions for Keras:\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6318, 187, 1), (6318,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.931],\n",
       "        [0.844],\n",
       "        [0.647],\n",
       "        ...,\n",
       "        [0.   ],\n",
       "        [0.   ],\n",
       "        [0.   ]],\n",
       "\n",
       "       [[1.   ],\n",
       "        [0.986],\n",
       "        [0.721],\n",
       "        ...,\n",
       "        [0.   ],\n",
       "        [0.   ],\n",
       "        [0.   ]],\n",
       "\n",
       "       [[1.   ],\n",
       "        [0.928],\n",
       "        [0.617],\n",
       "        ...,\n",
       "        [0.   ],\n",
       "        [0.   ],\n",
       "        [0.   ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.   ],\n",
       "        [0.951],\n",
       "        [0.495],\n",
       "        ...,\n",
       "        [0.   ],\n",
       "        [0.   ],\n",
       "        [0.   ]],\n",
       "\n",
       "       [[0.24 ],\n",
       "        [0.421],\n",
       "        [0.607],\n",
       "        ...,\n",
       "        [0.   ],\n",
       "        [0.   ],\n",
       "        [0.   ]],\n",
       "\n",
       "       [[0.927],\n",
       "        [0.767],\n",
       "        [0.595],\n",
       "        ...,\n",
       "        [0.   ],\n",
       "        [0.   ],\n",
       "        [0.   ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.581875\n",
       "4.0    0.178152\n",
       "2.0    0.160425\n",
       "1.0    0.061600\n",
       "3.0    0.017948\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Baseline\n",
    "data['Target'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a normal (cross-sectional) NN Model for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=0, input_shape=[187,1]),\n",
    "    keras.layers.Flatten(input_shape=[187, 1]),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.9292 - accuracy: 0.6701 - val_loss: 0.5879 - val_accuracy: 0.8010\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.8267 - val_loss: 0.4950 - val_accuracy: 0.8357\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8493 - val_loss: 0.4837 - val_accuracy: 0.8449\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8652 - val_loss: 0.4795 - val_accuracy: 0.8479\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8879 - val_loss: 0.4430 - val_accuracy: 0.8641\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8872 - val_loss: 0.4047 - val_accuracy: 0.8804\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8946 - val_loss: 0.4166 - val_accuracy: 0.8763\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8991 - val_loss: 0.4138 - val_accuracy: 0.8818\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.9051 - val_loss: 0.4408 - val_accuracy: 0.8604\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.9049 - val_loss: 0.6775 - val_accuracy: 0.7965\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.9022 - val_loss: 0.3710 - val_accuracy: 0.8885\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.9120 - val_loss: 0.4178 - val_accuracy: 0.8615\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.9116 - val_loss: 0.3912 - val_accuracy: 0.8818\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.9181 - val_loss: 0.4002 - val_accuracy: 0.8781\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.9151 - val_loss: 0.3724 - val_accuracy: 0.8918\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.9103 - val_loss: 0.3874 - val_accuracy: 0.8844\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.9129 - val_loss: 0.3890 - val_accuracy: 0.8811\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.9203 - val_loss: 0.3856 - val_accuracy: 0.8863\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.9092 - val_loss: 0.3929 - val_accuracy: 0.8807\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.9162 - val_loss: 0.3735 - val_accuracy: 0.8900\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9183 - val_loss: 0.3695 - val_accuracy: 0.8914\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9190 - val_loss: 0.4812 - val_accuracy: 0.8604\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9188 - val_loss: 0.3643 - val_accuracy: 0.8944\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9243 - val_loss: 0.3615 - val_accuracy: 0.8984\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.9183 - val_loss: 0.3701 - val_accuracy: 0.8948\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9268 - val_loss: 0.3595 - val_accuracy: 0.8940\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9221 - val_loss: 0.3742 - val_accuracy: 0.8896\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9189 - val_loss: 0.3865 - val_accuracy: 0.8929\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9238 - val_loss: 0.3958 - val_accuracy: 0.8933\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9331 - val_loss: 0.3918 - val_accuracy: 0.8936\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9309 - val_loss: 0.4416 - val_accuracy: 0.8575\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9275 - val_loss: 0.3683 - val_accuracy: 0.8962\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.9301 - val_loss: 0.3746 - val_accuracy: 0.8881\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9297 - val_loss: 0.3834 - val_accuracy: 0.8903\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9310 - val_loss: 0.3764 - val_accuracy: 0.8996\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9319 - val_loss: 0.3907 - val_accuracy: 0.9014\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9297 - val_loss: 0.4196 - val_accuracy: 0.8874\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9331 - val_loss: 0.3957 - val_accuracy: 0.8966\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9265 - val_loss: 0.3894 - val_accuracy: 0.8881\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9350 - val_loss: 0.3755 - val_accuracy: 0.8918\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9317 - val_loss: 0.3888 - val_accuracy: 0.8837\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9297 - val_loss: 0.4402 - val_accuracy: 0.8774\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9345 - val_loss: 0.3891 - val_accuracy: 0.9040\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9274 - val_loss: 0.3514 - val_accuracy: 0.9084\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9343 - val_loss: 0.3773 - val_accuracy: 0.9003\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9333 - val_loss: 0.3629 - val_accuracy: 0.9018\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9325 - val_loss: 0.3674 - val_accuracy: 0.8984\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9334 - val_loss: 0.3592 - val_accuracy: 0.9066\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9362 - val_loss: 0.3970 - val_accuracy: 0.8925\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9349 - val_loss: 0.3637 - val_accuracy: 0.9069\n"
     ]
    }
   ],
   "source": [
    "# Fitting Model\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.36\n",
      "accuracy: 90.69%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "scores\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "\n",
    "### Make sure to add the masking layer to the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building Model\n",
    "n_steps = 187\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.LSTM(10),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "198/198 [==============================] - 68s 294ms/step - loss: 1.2269 - accuracy: 0.5835 - val_loss: 1.0934 - val_accuracy: 0.5735\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 57s 289ms/step - loss: 1.0684 - accuracy: 0.5846 - val_loss: 1.1179 - val_accuracy: 0.4900\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 49s 248ms/step - loss: 1.0618 - accuracy: 0.5868 - val_loss: 1.0803 - val_accuracy: 0.5757\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 52s 264ms/step - loss: 1.0405 - accuracy: 0.6063 - val_loss: 1.0303 - val_accuracy: 0.6182\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 50s 253ms/step - loss: 0.9433 - accuracy: 0.6721 - val_loss: 0.9137 - val_accuracy: 0.7049\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 66s 334ms/step - loss: 0.8892 - accuracy: 0.7086 - val_loss: 0.8435 - val_accuracy: 0.7138\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 73s 368ms/step - loss: 0.8107 - accuracy: 0.7305 - val_loss: 0.8134 - val_accuracy: 0.7267\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 73s 369ms/step - loss: 0.7489 - accuracy: 0.7489 - val_loss: 0.7889 - val_accuracy: 0.7297\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 73s 367ms/step - loss: 0.7124 - accuracy: 0.7595 - val_loss: 0.7082 - val_accuracy: 0.7666\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 73s 367ms/step - loss: 0.6950 - accuracy: 0.7602 - val_loss: 0.7180 - val_accuracy: 0.7592\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 79s 400ms/step - loss: 0.6619 - accuracy: 0.7838 - val_loss: 0.6476 - val_accuracy: 0.7899\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 364s 2s/step - loss: 0.6924 - accuracy: 0.7793 - val_loss: 0.6716 - val_accuracy: 0.7858\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 54s 274ms/step - loss: 0.6176 - accuracy: 0.8087 - val_loss: 0.7303 - val_accuracy: 0.7666\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 50s 254ms/step - loss: 0.5993 - accuracy: 0.8096 - val_loss: 0.6339 - val_accuracy: 0.7980\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 48s 242ms/step - loss: 0.5849 - accuracy: 0.8156 - val_loss: 0.8545 - val_accuracy: 0.6809\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 48s 245ms/step - loss: 0.6767 - accuracy: 0.7715 - val_loss: 0.6257 - val_accuracy: 0.7936\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 47s 239ms/step - loss: 0.5894 - accuracy: 0.8129 - val_loss: 0.5576 - val_accuracy: 0.8135\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 47s 240ms/step - loss: 0.5470 - accuracy: 0.8263 - val_loss: 0.5559 - val_accuracy: 0.8227\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 50s 251ms/step - loss: 0.5463 - accuracy: 0.8288 - val_loss: 0.5320 - val_accuracy: 0.8316\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 49s 249ms/step - loss: 0.5447 - accuracy: 0.8265 - val_loss: 0.5597 - val_accuracy: 0.8179\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 49s 247ms/step - loss: 0.8209 - accuracy: 0.7231 - val_loss: 0.6072 - val_accuracy: 0.8069\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 49s 245ms/step - loss: 0.5757 - accuracy: 0.8179 - val_loss: 0.5533 - val_accuracy: 0.8231\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 49s 246ms/step - loss: 0.5011 - accuracy: 0.8451 - val_loss: 0.5512 - val_accuracy: 0.8338\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 49s 245ms/step - loss: 0.4915 - accuracy: 0.8475 - val_loss: 0.5146 - val_accuracy: 0.8375\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 47s 238ms/step - loss: 0.4913 - accuracy: 0.8456 - val_loss: 0.5440 - val_accuracy: 0.8261\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 47s 238ms/step - loss: 0.4773 - accuracy: 0.8495 - val_loss: 0.5126 - val_accuracy: 0.8401\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 47s 235ms/step - loss: 0.4665 - accuracy: 0.8537 - val_loss: 0.5116 - val_accuracy: 0.8386\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 47s 236ms/step - loss: 0.4802 - accuracy: 0.8393 - val_loss: 0.5532 - val_accuracy: 0.8309\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 47s 236ms/step - loss: 0.4907 - accuracy: 0.8475 - val_loss: 0.5492 - val_accuracy: 0.8290\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 47s 236ms/step - loss: 0.4519 - accuracy: 0.8575 - val_loss: 0.4758 - val_accuracy: 0.8460\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 47s 236ms/step - loss: 0.4436 - accuracy: 0.8627 - val_loss: 0.5445 - val_accuracy: 0.8239\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 46s 235ms/step - loss: 0.4178 - accuracy: 0.8739 - val_loss: 0.4897 - val_accuracy: 0.8475\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 50s 250ms/step - loss: 0.4029 - accuracy: 0.8750 - val_loss: 0.5086 - val_accuracy: 0.8401\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 46s 235ms/step - loss: 0.4280 - accuracy: 0.8667 - val_loss: 0.5364 - val_accuracy: 0.8272\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 44s 223ms/step - loss: 0.4569 - accuracy: 0.8526 - val_loss: 0.4611 - val_accuracy: 0.8637\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 45s 225ms/step - loss: 0.3987 - accuracy: 0.8797 - val_loss: 0.4903 - val_accuracy: 0.8468\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 48s 241ms/step - loss: 0.4124 - accuracy: 0.8733 - val_loss: 0.4800 - val_accuracy: 0.8534\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 46s 233ms/step - loss: 0.4073 - accuracy: 0.8768 - val_loss: 0.4366 - val_accuracy: 0.8700\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 46s 231ms/step - loss: 0.3857 - accuracy: 0.8808 - val_loss: 0.5265 - val_accuracy: 0.8364\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 46s 231ms/step - loss: 0.3992 - accuracy: 0.8799 - val_loss: 0.5303 - val_accuracy: 0.8397\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 45s 228ms/step - loss: 0.4096 - accuracy: 0.8762 - val_loss: 0.5193 - val_accuracy: 0.8371\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 46s 234ms/step - loss: 0.4247 - accuracy: 0.8731 - val_loss: 0.5466 - val_accuracy: 0.8364\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 46s 232ms/step - loss: 0.4435 - accuracy: 0.8702 - val_loss: 0.4317 - val_accuracy: 0.8748\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 46s 232ms/step - loss: 0.4144 - accuracy: 0.8720 - val_loss: 0.4978 - val_accuracy: 0.8493\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 46s 233ms/step - loss: 0.4295 - accuracy: 0.8616 - val_loss: 0.4284 - val_accuracy: 0.8730\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 46s 231ms/step - loss: 0.3628 - accuracy: 0.8896 - val_loss: 0.4080 - val_accuracy: 0.8785\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 46s 234ms/step - loss: 0.3661 - accuracy: 0.8855 - val_loss: 0.4522 - val_accuracy: 0.8630\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 46s 233ms/step - loss: 0.3609 - accuracy: 0.8915 - val_loss: 0.3968 - val_accuracy: 0.8804\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 46s 233ms/step - loss: 0.3612 - accuracy: 0.8925 - val_loss: 0.4063 - val_accuracy: 0.8792\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 46s 233ms/step - loss: 0.3504 - accuracy: 0.8903 - val_loss: 0.4233 - val_accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "#Fitting Model\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.42\n",
      "accuracy: 87.22%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model\n",
    "\n",
    "### Make sure to add the masking layer to this model too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "n_steps = 187\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "198/198 [==============================] - 72s 312ms/step - loss: 1.2975 - accuracy: 0.5271 - val_loss: 1.0522 - val_accuracy: 0.5894\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 1.0147 - accuracy: 0.6127 - val_loss: 0.9108 - val_accuracy: 0.6979\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.8326 - accuracy: 0.7235 - val_loss: 0.7328 - val_accuracy: 0.7770\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.7071 - accuracy: 0.7833 - val_loss: 0.6672 - val_accuracy: 0.7943\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 59s 301ms/step - loss: 0.6397 - accuracy: 0.8058 - val_loss: 0.6478 - val_accuracy: 0.8013\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.6202 - accuracy: 0.8065 - val_loss: 0.6348 - val_accuracy: 0.8047\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 59s 296ms/step - loss: 0.5779 - accuracy: 0.8254 - val_loss: 0.5890 - val_accuracy: 0.8179\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 59s 297ms/step - loss: 0.5322 - accuracy: 0.8380 - val_loss: 0.5777 - val_accuracy: 0.8205\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.5323 - accuracy: 0.8353 - val_loss: 0.5711 - val_accuracy: 0.8165\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 61s 308ms/step - loss: 0.5081 - accuracy: 0.8427 - val_loss: 0.5227 - val_accuracy: 0.8301\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 60s 304ms/step - loss: 0.4797 - accuracy: 0.8478 - val_loss: 0.5204 - val_accuracy: 0.8349\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 60s 305ms/step - loss: 0.4926 - accuracy: 0.8406 - val_loss: 0.4969 - val_accuracy: 0.8416\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.4578 - accuracy: 0.8550 - val_loss: 0.4808 - val_accuracy: 0.8479\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 58s 295ms/step - loss: 0.4253 - accuracy: 0.8656 - val_loss: 0.5667 - val_accuracy: 0.8161\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.4209 - accuracy: 0.8702 - val_loss: 0.4517 - val_accuracy: 0.8516\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.4227 - accuracy: 0.8716 - val_loss: 0.4519 - val_accuracy: 0.8530\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 58s 293ms/step - loss: 0.4052 - accuracy: 0.8720 - val_loss: 0.4330 - val_accuracy: 0.8541\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.3883 - accuracy: 0.8779 - val_loss: 0.4348 - val_accuracy: 0.8538\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.3831 - accuracy: 0.8764 - val_loss: 0.4098 - val_accuracy: 0.8619\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 59s 297ms/step - loss: 0.3784 - accuracy: 0.8754 - val_loss: 0.4017 - val_accuracy: 0.8641\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 60s 301ms/step - loss: 0.3686 - accuracy: 0.8813 - val_loss: 0.3970 - val_accuracy: 0.8641\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 58s 292ms/step - loss: 0.3583 - accuracy: 0.8835 - val_loss: 0.4311 - val_accuracy: 0.8608\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.3526 - accuracy: 0.8848 - val_loss: 0.3868 - val_accuracy: 0.8752\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 58s 295ms/step - loss: 0.3429 - accuracy: 0.8931 - val_loss: 0.4078 - val_accuracy: 0.8660\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.3475 - accuracy: 0.8916 - val_loss: 0.3822 - val_accuracy: 0.8811\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 59s 300ms/step - loss: 0.3274 - accuracy: 0.8973 - val_loss: 0.3725 - val_accuracy: 0.8807\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 60s 301ms/step - loss: 0.3385 - accuracy: 0.8914 - val_loss: 0.4584 - val_accuracy: 0.8538\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 59s 297ms/step - loss: 0.3222 - accuracy: 0.8949 - val_loss: 0.3946 - val_accuracy: 0.8678\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 59s 296ms/step - loss: 0.3148 - accuracy: 0.9002 - val_loss: 0.3545 - val_accuracy: 0.8951\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 59s 296ms/step - loss: 0.2991 - accuracy: 0.9044 - val_loss: 0.3583 - val_accuracy: 0.8936\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.2987 - accuracy: 0.9047 - val_loss: 0.3570 - val_accuracy: 0.8844\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 59s 297ms/step - loss: 0.2934 - accuracy: 0.9114 - val_loss: 0.3613 - val_accuracy: 0.8885\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 59s 300ms/step - loss: 0.2760 - accuracy: 0.9125 - val_loss: 0.3310 - val_accuracy: 0.9021\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 59s 299ms/step - loss: 0.2735 - accuracy: 0.9164 - val_loss: 0.3349 - val_accuracy: 0.8973\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 59s 297ms/step - loss: 0.2684 - accuracy: 0.9162 - val_loss: 0.3446 - val_accuracy: 0.8992\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 60s 305ms/step - loss: 0.2628 - accuracy: 0.9198 - val_loss: 0.3328 - val_accuracy: 0.9014\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.2718 - accuracy: 0.9185 - val_loss: 0.3278 - val_accuracy: 0.8970\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 59s 300ms/step - loss: 0.2630 - accuracy: 0.9218 - val_loss: 0.3207 - val_accuracy: 0.9055\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 59s 299ms/step - loss: 0.2543 - accuracy: 0.9235 - val_loss: 0.3327 - val_accuracy: 0.9066\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 59s 299ms/step - loss: 0.2405 - accuracy: 0.9285 - val_loss: 0.3118 - val_accuracy: 0.9073\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 59s 300ms/step - loss: 0.2442 - accuracy: 0.9296 - val_loss: 0.3123 - val_accuracy: 0.9103\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 59s 298ms/step - loss: 0.2464 - accuracy: 0.9247 - val_loss: 0.3395 - val_accuracy: 0.9047\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 59s 300ms/step - loss: 0.2636 - accuracy: 0.9221 - val_loss: 0.2953 - val_accuracy: 0.9177\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 59s 299ms/step - loss: 0.2415 - accuracy: 0.9249 - val_loss: 0.2940 - val_accuracy: 0.9136\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 60s 302ms/step - loss: 0.2358 - accuracy: 0.9278 - val_loss: 0.3021 - val_accuracy: 0.9095\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 61s 309ms/step - loss: 0.2204 - accuracy: 0.9345 - val_loss: 0.2968 - val_accuracy: 0.9136\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 61s 310ms/step - loss: 0.2337 - accuracy: 0.9298 - val_loss: 0.3281 - val_accuracy: 0.9055\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 66s 336ms/step - loss: 0.2205 - accuracy: 0.9329 - val_loss: 0.3038 - val_accuracy: 0.9110\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 58s 294ms/step - loss: 0.2202 - accuracy: 0.9335 - val_loss: 0.2912 - val_accuracy: 0.9165\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 60s 304ms/step - loss: 0.2136 - accuracy: 0.9372 - val_loss: 0.3275 - val_accuracy: 0.9021\n"
     ]
    }
   ],
   "source": [
    "#Fitting Model\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.33\n",
      "accuracy: 90.21%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GRU Model performs the best as the model accuracy is  test data is 90.21% in predicting multiclass heart condition target variable (The baseline is 58.18%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
